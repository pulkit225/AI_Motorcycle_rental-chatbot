{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing Physical Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Used in Tensorflow Model\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import random\n",
    "\n",
    "# used to for Contextualisation and Other NLP Tasks.\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "#Other\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the data to words, classes, documents and ignore words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        \n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        \n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        \n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        \n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming, case folding and Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 documents\n",
      "9 classes ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
      "48 unique stemmed words [\"'d\", \"'s\", 'a', 'acceiv', 'anyon', 'ar', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hi', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'of', 'on', 'op', 'rent', 'see', 'tak', 'thank', 'that', 'ther', 'thi', 'to', 'today', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a bag of words for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "output_empty = [0] * len(classes)\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Randomly and Converting into Numpy Array for Faster Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# Creating Train and Test Lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "\n",
    "# Building Neural Network for Out Chatbot to be Contextual\n",
    "# Resetting graph data\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: FGG452\n",
      "Log directory: tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 27\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.825s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 27/27\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m1.97750\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 002 | loss: 1.97750 - acc: 0.1667 -- iter: 27/27\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m2.15715\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 003 | loss: 2.15715 - acc: 0.1818 -- iter: 27/27\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m2.18696\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 004 | loss: 2.18696 - acc: 0.1843 -- iter: 27/27\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m2.19371\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 005 | loss: 2.19371 - acc: 0.1849 -- iter: 27/27\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m2.19552\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 006 | loss: 2.19552 - acc: 0.1851 -- iter: 27/27\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m2.19602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 007 | loss: 2.19602 - acc: 0.1851 -- iter: 27/27\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m2.19609\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 008 | loss: 2.19609 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m2.19602\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 009 | loss: 2.19602 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m2.19589\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 010 | loss: 2.19589 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m2.19573\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 011 | loss: 2.19573 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m2.19555\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 012 | loss: 2.19555 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m2.19536\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 013 | loss: 2.19536 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m2.19517\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 014 | loss: 2.19517 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m2.19496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 015 | loss: 2.19496 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m2.19475\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 016 | loss: 2.19475 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m2.19453\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 017 | loss: 2.19453 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m2.19430\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 018 | loss: 2.19430 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m2.19430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 019 | loss: 2.19430 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m2.19398\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 020 | loss: 2.19398 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m2.19368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 021 | loss: 2.19368 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m2.19339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 022 | loss: 2.19339 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m2.19310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 023 | loss: 2.19310 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m2.19280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 024 | loss: 2.19280 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m2.19249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 025 | loss: 2.19249 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m2.19217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 026 | loss: 2.19217 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m2.19184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 027 | loss: 2.19184 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m2.19149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 028 | loss: 2.19149 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m2.19113\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 029 | loss: 2.19113 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m2.19074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 030 | loss: 2.19074 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m2.19034\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 031 | loss: 2.19034 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m2.18991\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 032 | loss: 2.18991 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m2.18947\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 033 | loss: 2.18947 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m2.18899\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 034 | loss: 2.18899 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m2.18849\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 035 | loss: 2.18849 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m2.18797\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 036 | loss: 2.18797 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m2.18741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 037 | loss: 2.18741 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m2.18683\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 038 | loss: 2.18683 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m2.18621\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 039 | loss: 2.18621 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m2.18556\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 040 | loss: 2.18556 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m2.18487\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 041 | loss: 2.18487 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m2.18414\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 042 | loss: 2.18414 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m2.18338\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 043 | loss: 2.18338 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m2.18413\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 044 | loss: 2.18413 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m2.18304\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 045 | loss: 2.18304 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m2.18196\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 046 | loss: 2.18196 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m2.18088\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 047 | loss: 2.18088 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m2.17980\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 048 | loss: 2.17980 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m2.17869\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 049 | loss: 2.17869 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m2.17962\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 050 | loss: 2.17962 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m2.17816\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 051 | loss: 2.17816 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m2.17925\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 052 | loss: 2.17925 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m2.17747\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 053 | loss: 2.17747 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m2.17894\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 054 | loss: 2.17894 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m2.17685\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 055 | loss: 2.17685 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m2.17763\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 056 | loss: 2.17763 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m2.17539\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 057 | loss: 2.17539 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m2.17615\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 058 | loss: 2.17615 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m2.17377\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 059 | loss: 2.17377 - acc: 0.1852 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m2.17568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 060 | loss: 2.17568 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m2.17303\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 061 | loss: 2.17303 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m2.17055\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 062 | loss: 2.17055 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m2.16821\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 063 | loss: 2.16821 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m2.16594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 064 | loss: 2.16594 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m2.16373\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 065 | loss: 2.16373 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m2.16595\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 066 | loss: 2.16595 - acc: 0.1852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m2.16328\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 067 | loss: 2.16328 - acc: 0.1896 -- iter: 27/27\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m2.16466\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 068 | loss: 2.16466 - acc: 0.1891 -- iter: 27/27\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m2.16171\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 069 | loss: 2.16171 - acc: 0.1930 -- iter: 27/27\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m2.15886\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 070 | loss: 2.15886 - acc: 0.1963 -- iter: 27/27\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m2.15610\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 071 | loss: 2.15610 - acc: 0.1993 -- iter: 27/27\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m2.15338\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 072 | loss: 2.15338 - acc: 0.2019 -- iter: 27/27\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m2.15068\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 073 | loss: 2.15068 - acc: 0.2041 -- iter: 27/27\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m2.15362\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 074 | loss: 2.15362 - acc: 0.1980 -- iter: 27/27\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m2.15033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 075 | loss: 2.15033 - acc: 0.2006 -- iter: 27/27\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m2.15468\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 076 | loss: 2.15468 - acc: 0.1950 -- iter: 27/27\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m2.15076\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 077 | loss: 2.15076 - acc: 0.1979 -- iter: 27/27\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m2.15358\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 078 | loss: 2.15358 - acc: 0.1966 -- iter: 27/27\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m2.14928\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 079 | loss: 2.14928 - acc: 0.2030 -- iter: 27/27\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m2.15179\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 080 | loss: 2.15179 - acc: 0.1974 -- iter: 27/27\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m2.14720\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 081 | loss: 2.14720 - acc: 0.2037 -- iter: 27/27\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m2.14281\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 082 | loss: 2.14281 - acc: 0.2129 -- iter: 27/27\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m2.13854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 083 | loss: 2.13854 - acc: 0.2213 -- iter: 27/27\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m2.13435\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 084 | loss: 2.13435 - acc: 0.2288 -- iter: 27/27\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m2.13020\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 085 | loss: 2.13020 - acc: 0.2355 -- iter: 27/27\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m2.12606\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 086 | loss: 2.12606 - acc: 0.2416 -- iter: 27/27\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m2.12191\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 087 | loss: 2.12191 - acc: 0.2471 -- iter: 27/27\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m2.11773\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 088 | loss: 2.11773 - acc: 0.2520 -- iter: 27/27\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m2.11350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 089 | loss: 2.11350 - acc: 0.2564 -- iter: 27/27\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m2.10921\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 090 | loss: 2.10921 - acc: 0.2604 -- iter: 27/27\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m2.10482\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 091 | loss: 2.10482 - acc: 0.2640 -- iter: 27/27\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m2.10035\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 092 | loss: 2.10035 - acc: 0.2672 -- iter: 27/27\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m2.09576\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 093 | loss: 2.09576 - acc: 0.2701 -- iter: 27/27\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m2.10226\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 094 | loss: 2.10226 - acc: 0.2653 -- iter: 27/27\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m2.09637\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 095 | loss: 2.09637 - acc: 0.2684 -- iter: 27/27\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m2.09050\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 096 | loss: 2.09050 - acc: 0.2712 -- iter: 27/27\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m2.08463\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 097 | loss: 2.08463 - acc: 0.2737 -- iter: 27/27\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m2.07873\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 098 | loss: 2.07873 - acc: 0.2760 -- iter: 27/27\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m2.07279\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 099 | loss: 2.07279 - acc: 0.2780 -- iter: 27/27\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m2.06677\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 100 | loss: 2.06677 - acc: 0.2798 -- iter: 27/27\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m2.06067\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 101 | loss: 2.06067 - acc: 0.2852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m2.07117\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 102 | loss: 2.07117 - acc: 0.2715 -- iter: 27/27\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m2.06329\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 103 | loss: 2.06329 - acc: 0.2777 -- iter: 27/27\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m2.05552\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 104 | loss: 2.05552 - acc: 0.2832 -- iter: 27/27\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m2.04783\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 105 | loss: 2.04783 - acc: 0.2883 -- iter: 27/27\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m2.04019\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 106 | loss: 2.04019 - acc: 0.2928 -- iter: 27/27\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m2.03257\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 107 | loss: 2.03257 - acc: 0.2968 -- iter: 27/27\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m2.02493\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 108 | loss: 2.02493 - acc: 0.3005 -- iter: 27/27\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m2.01726\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 109 | loss: 2.01726 - acc: 0.3038 -- iter: 27/27\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m2.00953\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 110 | loss: 2.00953 - acc: 0.3067 -- iter: 27/27\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m2.00174\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 111 | loss: 2.00174 - acc: 0.3094 -- iter: 27/27\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.99386\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 112 | loss: 1.99386 - acc: 0.3118 -- iter: 27/27\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.98589\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 113 | loss: 1.98589 - acc: 0.3139 -- iter: 27/27\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.97782\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 114 | loss: 1.97782 - acc: 0.3159 -- iter: 27/27\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.96963\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 115 | loss: 1.96963 - acc: 0.3176 -- iter: 27/27\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.99341\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 116 | loss: 1.99341 - acc: 0.3044 -- iter: 27/27\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m1.98192\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 117 | loss: 1.98192 - acc: 0.3073 -- iter: 27/27\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m1.97075\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 118 | loss: 1.97075 - acc: 0.3099 -- iter: 27/27\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m1.95984\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 119 | loss: 1.95984 - acc: 0.3122 -- iter: 27/27\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m1.94914\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 120 | loss: 1.94914 - acc: 0.3143 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m1.93860\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 121 | loss: 1.93860 - acc: 0.3162 -- iter: 27/27\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m1.92819\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 122 | loss: 1.92819 - acc: 0.3179 -- iter: 27/27\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m1.91787\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 123 | loss: 1.91787 - acc: 0.3195 -- iter: 27/27\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m1.90763\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 124 | loss: 1.90763 - acc: 0.3209 -- iter: 27/27\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m1.89744\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 125 | loss: 1.89744 - acc: 0.3221 -- iter: 27/27\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m1.93872\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 126 | loss: 1.93872 - acc: 0.3047 -- iter: 27/27\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m1.92363\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 127 | loss: 1.92363 - acc: 0.3113 -- iter: 27/27\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m1.90921\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 128 | loss: 1.90921 - acc: 0.3172 -- iter: 27/27\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m1.89537\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 129 | loss: 1.89537 - acc: 0.3225 -- iter: 27/27\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m1.92766\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 130 | loss: 1.92766 - acc: 0.3088 -- iter: 27/27\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m1.91035\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 131 | loss: 1.91035 - acc: 0.3149 -- iter: 27/27\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m1.89400\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 132 | loss: 1.89400 - acc: 0.3205 -- iter: 27/27\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m1.87846\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 133 | loss: 1.87846 - acc: 0.3255 -- iter: 27/27\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m1.92639\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 134 | loss: 1.92639 - acc: 0.3003 -- iter: 27/27\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m1.90614\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 135 | loss: 1.90614 - acc: 0.3073 -- iter: 27/27\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m1.88722\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 136 | loss: 1.88722 - acc: 0.3136 -- iter: 27/27\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m1.86946\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 137 | loss: 1.86946 - acc: 0.3193 -- iter: 27/27\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m1.90145\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 138 | loss: 1.90145 - acc: 0.3022 -- iter: 27/27\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m1.88086\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 139 | loss: 1.88086 - acc: 0.3127 -- iter: 27/27\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m1.86165\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 140 | loss: 1.86165 - acc: 0.3222 -- iter: 27/27\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m1.84365\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 141 | loss: 1.84365 - acc: 0.3307 -- iter: 27/27\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m1.82669\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 142 | loss: 1.82669 - acc: 0.3384 -- iter: 27/27\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m1.81064\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 143 | loss: 1.81064 - acc: 0.3453 -- iter: 27/27\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m1.79539\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 144 | loss: 1.79539 - acc: 0.3515 -- iter: 27/27\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m1.78083\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 145 | loss: 1.78083 - acc: 0.3571 -- iter: 27/27\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m1.76688\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 146 | loss: 1.76688 - acc: 0.3621 -- iter: 27/27\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m1.75346\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 147 | loss: 1.75346 - acc: 0.3666 -- iter: 27/27\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m1.74050\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 148 | loss: 1.74050 - acc: 0.3707 -- iter: 27/27\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m1.72795\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 149 | loss: 1.72795 - acc: 0.3744 -- iter: 27/27\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m1.78728\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 150 | loss: 1.78728 - acc: 0.3481 -- iter: 27/27\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m1.76843\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 151 | loss: 1.76843 - acc: 0.3540 -- iter: 27/27\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m1.75074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 152 | loss: 1.75074 - acc: 0.3630 -- iter: 27/27\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m1.73405\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 153 | loss: 1.73405 - acc: 0.3712 -- iter: 27/27\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m1.71824\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 154 | loss: 1.71824 - acc: 0.3785 -- iter: 27/27\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m1.70322\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 155 | loss: 1.70322 - acc: 0.3851 -- iter: 27/27\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m1.68889\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 156 | loss: 1.68889 - acc: 0.3910 -- iter: 27/27\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m1.67517\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 157 | loss: 1.67517 - acc: 0.3964 -- iter: 27/27\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m1.66198\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 158 | loss: 1.66198 - acc: 0.4012 -- iter: 27/27\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m1.64926\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 159 | loss: 1.64926 - acc: 0.4055 -- iter: 27/27\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m1.63697\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 160 | loss: 1.63697 - acc: 0.4094 -- iter: 27/27\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m1.62506\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 161 | loss: 1.62506 - acc: 0.4129 -- iter: 27/27\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m1.61347\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 162 | loss: 1.61347 - acc: 0.4161 -- iter: 27/27\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m1.60219\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 163 | loss: 1.60219 - acc: 0.4189 -- iter: 27/27\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m1.59117\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 164 | loss: 1.59117 - acc: 0.4215 -- iter: 27/27\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m1.58039\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 165 | loss: 1.58039 - acc: 0.4238 -- iter: 27/27\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m1.56984\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 166 | loss: 1.56984 - acc: 0.4258 -- iter: 27/27\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m1.55948\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 167 | loss: 1.55948 - acc: 0.4277 -- iter: 27/27\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m1.54930\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 168 | loss: 1.54930 - acc: 0.4294 -- iter: 27/27\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m1.53929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 169 | loss: 1.53929 - acc: 0.4309 -- iter: 27/27\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m1.52944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 170 | loss: 1.52944 - acc: 0.4322 -- iter: 27/27\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m1.51973\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 171 | loss: 1.51973 - acc: 0.4334 -- iter: 27/27\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m1.51015\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 172 | loss: 1.51015 - acc: 0.4345 -- iter: 27/27\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m1.50070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 173 | loss: 1.50070 - acc: 0.4392 -- iter: 27/27\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m1.49137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 174 | loss: 1.49137 - acc: 0.4435 -- iter: 27/27\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m1.48215\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 175 | loss: 1.48215 - acc: 0.4473 -- iter: 27/27\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m1.47303\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 176 | loss: 1.47303 - acc: 0.4507 -- iter: 27/27\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m1.46402\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 177 | loss: 1.46402 - acc: 0.4575 -- iter: 27/27\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m1.45511\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 178 | loss: 1.45511 - acc: 0.4636 -- iter: 27/27\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m1.44629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 179 | loss: 1.44629 - acc: 0.4691 -- iter: 27/27\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m1.43756\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 180 | loss: 1.43756 - acc: 0.4740 -- iter: 27/27\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m1.42892\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 181 | loss: 1.42892 - acc: 0.4785 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m1.42037\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 182 | loss: 1.42037 - acc: 0.4825 -- iter: 27/27\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m1.41190\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 183 | loss: 1.41190 - acc: 0.4861 -- iter: 27/27\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m1.40351\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 184 | loss: 1.40351 - acc: 0.4930 -- iter: 27/27\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m1.39519\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 185 | loss: 1.39519 - acc: 0.4993 -- iter: 27/27\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m1.38696\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 186 | loss: 1.38696 - acc: 0.5049 -- iter: 27/27\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m1.37880\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 187 | loss: 1.37880 - acc: 0.5100 -- iter: 27/27\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m1.37071\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 188 | loss: 1.37071 - acc: 0.5145 -- iter: 27/27\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m1.36269\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 189 | loss: 1.36269 - acc: 0.5186 -- iter: 27/27\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m1.35474\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 190 | loss: 1.35474 - acc: 0.5223 -- iter: 27/27\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m1.34686\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 191 | loss: 1.34686 - acc: 0.5256 -- iter: 27/27\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m1.45526\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 192 | loss: 1.45526 - acc: 0.4953 -- iter: 27/27\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m1.43605\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 193 | loss: 1.43605 - acc: 0.5050 -- iter: 27/27\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m1.41820\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 194 | loss: 1.41820 - acc: 0.5138 -- iter: 27/27\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m1.40156\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 195 | loss: 1.40156 - acc: 0.5217 -- iter: 27/27\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m1.38599\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 196 | loss: 1.38599 - acc: 0.5288 -- iter: 27/27\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m1.37140\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 197 | loss: 1.37140 - acc: 0.5351 -- iter: 27/27\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m1.35767\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 198 | loss: 1.35767 - acc: 0.5409 -- iter: 27/27\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m1.34470\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 199 | loss: 1.34470 - acc: 0.5461 -- iter: 27/27\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m1.33241\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 200 | loss: 1.33241 - acc: 0.5507 -- iter: 27/27\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m1.32074\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 201 | loss: 1.32074 - acc: 0.5549 -- iter: 27/27\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m1.30962\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 202 | loss: 1.30962 - acc: 0.5587 -- iter: 27/27\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m1.29898\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 203 | loss: 1.29898 - acc: 0.5621 -- iter: 27/27\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m1.47839\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 204 | loss: 1.47839 - acc: 0.5207 -- iter: 27/27\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m1.44985\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 205 | loss: 1.44985 - acc: 0.5279 -- iter: 27/27\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m1.42376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 206 | loss: 1.42376 - acc: 0.5343 -- iter: 27/27\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m1.39982\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 207 | loss: 1.39982 - acc: 0.5402 -- iter: 27/27\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m1.57493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 208 | loss: 1.57493 - acc: 0.5047 -- iter: 27/27\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m1.53515\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 209 | loss: 1.53515 - acc: 0.5135 -- iter: 27/27\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m1.49902\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 210 | loss: 1.49902 - acc: 0.5251 -- iter: 27/27\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m1.46617\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 211 | loss: 1.46617 - acc: 0.5392 -- iter: 27/27\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m1.43624\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 212 | loss: 1.43624 - acc: 0.5520 -- iter: 27/27\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m1.40890\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 213 | loss: 1.40890 - acc: 0.5634 -- iter: 27/27\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m1.38389\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 214 | loss: 1.38389 - acc: 0.5738 -- iter: 27/27\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m1.36093\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 215 | loss: 1.36093 - acc: 0.5831 -- iter: 27/27\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m1.33982\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 216 | loss: 1.33982 - acc: 0.5914 -- iter: 27/27\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m1.32034\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 217 | loss: 1.32034 - acc: 0.6026 -- iter: 27/27\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m1.30232\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 218 | loss: 1.30232 - acc: 0.6128 -- iter: 27/27\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m1.28560\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 219 | loss: 1.28560 - acc: 0.6218 -- iter: 27/27\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m1.27003\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 220 | loss: 1.27003 - acc: 0.6300 -- iter: 27/27\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m1.25550\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 221 | loss: 1.25550 - acc: 0.6411 -- iter: 27/27\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m1.24188\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 222 | loss: 1.24188 - acc: 0.6511 -- iter: 27/27\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m1.22908\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 223 | loss: 1.22908 - acc: 0.6600 -- iter: 27/27\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m1.21701\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 224 | loss: 1.21701 - acc: 0.6681 -- iter: 27/27\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m1.20558\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 225 | loss: 1.20558 - acc: 0.6754 -- iter: 27/27\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m1.46242\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 226 | loss: 1.46242 - acc: 0.6115 -- iter: 27/27\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m1.42560\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 227 | loss: 1.42560 - acc: 0.6245 -- iter: 27/27\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m1.39213\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 228 | loss: 1.39213 - acc: 0.6361 -- iter: 27/27\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m1.36165\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 229 | loss: 1.36165 - acc: 0.6466 -- iter: 27/27\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m1.33385\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 230 | loss: 1.33385 - acc: 0.6560 -- iter: 27/27\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m1.30843\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 231 | loss: 1.30843 - acc: 0.6644 -- iter: 27/27\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m1.28514\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 232 | loss: 1.28514 - acc: 0.6721 -- iter: 27/27\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m1.26374\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 233 | loss: 1.26374 - acc: 0.6789 -- iter: 27/27\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m1.46683\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 234 | loss: 1.46683 - acc: 0.6185 -- iter: 27/27\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m1.42655\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 235 | loss: 1.42655 - acc: 0.6344 -- iter: 27/27\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m1.39001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 236 | loss: 1.39001 - acc: 0.6487 -- iter: 27/27\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m1.35680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 237 | loss: 1.35680 - acc: 0.6616 -- iter: 27/27\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m1.32656\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 238 | loss: 1.32656 - acc: 0.6732 -- iter: 27/27\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m1.29898\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 239 | loss: 1.29898 - acc: 0.6837 -- iter: 27/27\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m1.27377\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 240 | loss: 1.27377 - acc: 0.6931 -- iter: 27/27\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m1.25067\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 241 | loss: 1.25067 - acc: 0.7016 -- iter: 27/27\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m1.22945\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 242 | loss: 1.22945 - acc: 0.7129 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m1.20992\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 243 | loss: 1.20992 - acc: 0.7231 -- iter: 27/27\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m1.19189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 244 | loss: 1.19189 - acc: 0.7323 -- iter: 27/27\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m1.17520\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 245 | loss: 1.17520 - acc: 0.7405 -- iter: 27/27\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m1.15970\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 246 | loss: 1.15970 - acc: 0.7479 -- iter: 27/27\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m1.14528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 247 | loss: 1.14528 - acc: 0.7546 -- iter: 27/27\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m1.31946\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 248 | loss: 1.31946 - acc: 0.6940 -- iter: 27/27\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m1.28824\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 249 | loss: 1.28824 - acc: 0.7061 -- iter: 27/27\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m1.25979\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 250 | loss: 1.25979 - acc: 0.7169 -- iter: 27/27\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m1.23383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 251 | loss: 1.23383 - acc: 0.7267 -- iter: 27/27\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m1.21007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 252 | loss: 1.21007 - acc: 0.7355 -- iter: 27/27\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m1.18829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 253 | loss: 1.18829 - acc: 0.7435 -- iter: 27/27\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m1.40663\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 254 | loss: 1.40663 - acc: 0.6765 -- iter: 27/27\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m1.36456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 255 | loss: 1.36456 - acc: 0.6904 -- iter: 27/27\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m1.32646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 256 | loss: 1.32646 - acc: 0.7028 -- iter: 27/27\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m1.29190\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 257 | loss: 1.29190 - acc: 0.7140 -- iter: 27/27\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m1.26050\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 258 | loss: 1.26050 - acc: 0.7241 -- iter: 27/27\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m1.23191\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 259 | loss: 1.23191 - acc: 0.7332 -- iter: 27/27\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m1.20585\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 260 | loss: 1.20585 - acc: 0.7413 -- iter: 27/27\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m1.18203\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 261 | loss: 1.18203 - acc: 0.7487 -- iter: 27/27\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m1.16022\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 262 | loss: 1.16022 - acc: 0.7553 -- iter: 27/27\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m1.14020\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 263 | loss: 1.14020 - acc: 0.7612 -- iter: 27/27\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m1.12178\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 264 | loss: 1.12178 - acc: 0.7666 -- iter: 27/27\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m1.10478\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 265 | loss: 1.10478 - acc: 0.7751 -- iter: 27/27\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m1.28887\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 266 | loss: 1.28887 - acc: 0.7124 -- iter: 27/27\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m1.25447\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 267 | loss: 1.25447 - acc: 0.7264 -- iter: 27/27\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m1.22323\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 268 | loss: 1.22323 - acc: 0.7389 -- iter: 27/27\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m1.19480\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 269 | loss: 1.19480 - acc: 0.7502 -- iter: 27/27\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m1.16889\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 270 | loss: 1.16889 - acc: 0.7604 -- iter: 27/27\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m1.14523\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 271 | loss: 1.14523 - acc: 0.7695 -- iter: 27/27\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m1.12357\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 272 | loss: 1.12357 - acc: 0.7778 -- iter: 27/27\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m1.10371\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 273 | loss: 1.10371 - acc: 0.7852 -- iter: 27/27\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m1.32168\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 274 | loss: 1.32168 - acc: 0.7066 -- iter: 27/27\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m1.28140\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 275 | loss: 1.28140 - acc: 0.7212 -- iter: 27/27\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m1.48083\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 276 | loss: 1.48083 - acc: 0.6676 -- iter: 27/27\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m1.42431\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 277 | loss: 1.42431 - acc: 0.6860 -- iter: 27/27\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m1.37333\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 278 | loss: 1.37333 - acc: 0.7026 -- iter: 27/27\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m1.32729\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 279 | loss: 1.32729 - acc: 0.7175 -- iter: 27/27\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m1.28567\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 280 | loss: 1.28567 - acc: 0.7309 -- iter: 27/27\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m1.24801\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 281 | loss: 1.24801 - acc: 0.7430 -- iter: 27/27\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m1.21387\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 282 | loss: 1.21387 - acc: 0.7539 -- iter: 27/27\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m1.18288\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 283 | loss: 1.18288 - acc: 0.7637 -- iter: 27/27\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m1.15471\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 284 | loss: 1.15471 - acc: 0.7725 -- iter: 27/27\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m1.12905\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 285 | loss: 1.12905 - acc: 0.7842 -- iter: 27/27\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m1.30633\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 286 | loss: 1.30633 - acc: 0.7280 -- iter: 27/27\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m1.26501\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 287 | loss: 1.26501 - acc: 0.7441 -- iter: 27/27\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m1.51006\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 288 | loss: 1.51006 - acc: 0.6771 -- iter: 27/27\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m1.44814\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 289 | loss: 1.44814 - acc: 0.6982 -- iter: 27/27\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m1.61862\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 290 | loss: 1.61862 - acc: 0.6469 -- iter: 27/27\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m1.54583\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 291 | loss: 1.54583 - acc: 0.6711 -- iter: 27/27\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m1.76936\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 292 | loss: 1.76936 - acc: 0.6040 -- iter: 27/27\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m1.68167\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 293 | loss: 1.68167 - acc: 0.6325 -- iter: 27/27\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m1.87016\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 294 | loss: 1.87016 - acc: 0.5767 -- iter: 27/27\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m1.77273\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 295 | loss: 1.77273 - acc: 0.6079 -- iter: 27/27\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m1.68522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 296 | loss: 1.68522 - acc: 0.6360 -- iter: 27/27\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m1.60658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 297 | loss: 1.60658 - acc: 0.6613 -- iter: 27/27\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m1.53585\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 298 | loss: 1.53585 - acc: 0.6840 -- iter: 27/27\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m1.47219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 299 | loss: 1.47219 - acc: 0.7045 -- iter: 27/27\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m1.41485\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 300 | loss: 1.41485 - acc: 0.7230 -- iter: 27/27\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m1.36316\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 301 | loss: 1.36316 - acc: 0.7396 -- iter: 27/27\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m1.31651\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 302 | loss: 1.31651 - acc: 0.7545 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m1.27436\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 303 | loss: 1.27436 - acc: 0.7679 -- iter: 27/27\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m1.23622\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 304 | loss: 1.23622 - acc: 0.7800 -- iter: 27/27\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m1.20168\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 305 | loss: 1.20168 - acc: 0.7909 -- iter: 27/27\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m1.17033\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 306 | loss: 1.17033 - acc: 0.8007 -- iter: 27/27\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m1.14185\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 307 | loss: 1.14185 - acc: 0.8095 -- iter: 27/27\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m1.11593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 308 | loss: 1.11593 - acc: 0.8175 -- iter: 27/27\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m1.09228\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 309 | loss: 1.09228 - acc: 0.8246 -- iter: 27/27\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m1.07067\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 310 | loss: 1.07067 - acc: 0.8310 -- iter: 27/27\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m1.05087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 311 | loss: 1.05087 - acc: 0.8368 -- iter: 27/27\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m1.03270\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 312 | loss: 1.03270 - acc: 0.8420 -- iter: 27/27\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m1.01599\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 313 | loss: 1.01599 - acc: 0.8467 -- iter: 27/27\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m1.00057\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 314 | loss: 1.00057 - acc: 0.8509 -- iter: 27/27\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.98632\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 315 | loss: 0.98632 - acc: 0.8547 -- iter: 27/27\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.97310\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 316 | loss: 0.97310 - acc: 0.8581 -- iter: 27/27\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.96080\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 317 | loss: 0.96080 - acc: 0.8612 -- iter: 27/27\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.94934\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 318 | loss: 0.94934 - acc: 0.8640 -- iter: 27/27\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.93862\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 319 | loss: 0.93862 - acc: 0.8665 -- iter: 27/27\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m1.21076\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 320 | loss: 1.21076 - acc: 0.7946 -- iter: 27/27\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m1.17328\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 321 | loss: 1.17328 - acc: 0.8041 -- iter: 27/27\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m1.13930\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 322 | loss: 1.13930 - acc: 0.8125 -- iter: 27/27\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m1.10846\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 323 | loss: 1.10846 - acc: 0.8202 -- iter: 27/27\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m1.08044\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 324 | loss: 1.08044 - acc: 0.8271 -- iter: 27/27\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m1.05492\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 325 | loss: 1.05492 - acc: 0.8369 -- iter: 27/27\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m1.03165\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 326 | loss: 1.03165 - acc: 0.8458 -- iter: 27/27\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m1.01039\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 327 | loss: 1.01039 - acc: 0.8538 -- iter: 27/27\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.99091\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 328 | loss: 0.99091 - acc: 0.8611 -- iter: 27/27\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.97305\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 329 | loss: 0.97305 - acc: 0.8675 -- iter: 27/27\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.95662\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 330 | loss: 0.95662 - acc: 0.8734 -- iter: 27/27\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.94147\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 331 | loss: 0.94147 - acc: 0.8786 -- iter: 27/27\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.92747\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 332 | loss: 0.92747 - acc: 0.8834 -- iter: 27/27\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.91450\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 333 | loss: 0.91450 - acc: 0.8876 -- iter: 27/27\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m1.11870\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 334 | loss: 1.11870 - acc: 0.8285 -- iter: 27/27\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m1.08599\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 335 | loss: 1.08599 - acc: 0.8382 -- iter: 27/27\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m1.05630\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 336 | loss: 1.05630 - acc: 0.8470 -- iter: 27/27\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m1.02930\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 337 | loss: 1.02930 - acc: 0.8549 -- iter: 27/27\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m1.00471\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 338 | loss: 1.00471 - acc: 0.8620 -- iter: 27/27\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.98228\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 339 | loss: 0.98228 - acc: 0.8684 -- iter: 27/27\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.96177\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 340 | loss: 0.96177 - acc: 0.8741 -- iter: 27/27\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.94300\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 341 | loss: 0.94300 - acc: 0.8793 -- iter: 27/27\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m1.19643\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 342 | loss: 1.19643 - acc: 0.8099 -- iter: 27/27\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m1.15368\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 343 | loss: 1.15368 - acc: 0.8215 -- iter: 27/27\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m1.11500\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 344 | loss: 1.11500 - acc: 0.8320 -- iter: 27/27\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m1.07997\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 345 | loss: 1.07997 - acc: 0.8413 -- iter: 27/27\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m1.04820\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 346 | loss: 1.04820 - acc: 0.8498 -- iter: 27/27\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m1.01935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 347 | loss: 1.01935 - acc: 0.8574 -- iter: 27/27\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.99311\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 348 | loss: 0.99311 - acc: 0.8643 -- iter: 27/27\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.96922\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 349 | loss: 0.96922 - acc: 0.8704 -- iter: 27/27\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.94741\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 350 | loss: 0.94741 - acc: 0.8760 -- iter: 27/27\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.92748\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 351 | loss: 0.92748 - acc: 0.8810 -- iter: 27/27\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.90922\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 352 | loss: 0.90922 - acc: 0.8855 -- iter: 27/27\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.89246\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 353 | loss: 0.89246 - acc: 0.8895 -- iter: 27/27\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.87704\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 354 | loss: 0.87704 - acc: 0.8932 -- iter: 27/27\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.86282\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 355 | loss: 0.86282 - acc: 0.8964 -- iter: 27/27\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.84967\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 356 | loss: 0.84967 - acc: 0.8994 -- iter: 27/27\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.83749\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 357 | loss: 0.83749 - acc: 0.9020 -- iter: 27/27\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m1.13288\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 358 | loss: 1.13288 - acc: 0.8229 -- iter: 27/27\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m1.09184\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 359 | loss: 1.09184 - acc: 0.8332 -- iter: 27/27\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m1.05470\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 360 | loss: 1.05470 - acc: 0.8425 -- iter: 27/27\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m1.02106\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 361 | loss: 1.02106 - acc: 0.8509 -- iter: 27/27\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m1.27921\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 362 | loss: 1.27921 - acc: 0.7880 -- iter: 27/27\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m1.22278\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 363 | loss: 1.22278 - acc: 0.8018 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m1.17186\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 364 | loss: 1.17186 - acc: 0.8142 -- iter: 27/27\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m1.12589\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 365 | loss: 1.12589 - acc: 0.8254 -- iter: 27/27\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m1.08433\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 366 | loss: 1.08433 - acc: 0.8354 -- iter: 27/27\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m1.04674\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 367 | loss: 1.04674 - acc: 0.8445 -- iter: 27/27\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m1.01268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 368 | loss: 1.01268 - acc: 0.8526 -- iter: 27/27\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.98181\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 369 | loss: 0.98181 - acc: 0.8600 -- iter: 27/27\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.95377\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 370 | loss: 0.95377 - acc: 0.8665 -- iter: 27/27\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.92827\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 371 | loss: 0.92827 - acc: 0.8725 -- iter: 27/27\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.90506\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 372 | loss: 0.90506 - acc: 0.8778 -- iter: 27/27\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.88388\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 373 | loss: 0.88388 - acc: 0.8826 -- iter: 27/27\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.86452\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 374 | loss: 0.86452 - acc: 0.8870 -- iter: 27/27\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.84680\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 375 | loss: 0.84680 - acc: 0.8909 -- iter: 27/27\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.83054\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 376 | loss: 0.83054 - acc: 0.8944 -- iter: 27/27\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.81559\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 377 | loss: 0.81559 - acc: 0.8975 -- iter: 27/27\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.80181\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 378 | loss: 0.80181 - acc: 0.9004 -- iter: 27/27\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.78908\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 379 | loss: 0.78908 - acc: 0.9029 -- iter: 27/27\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.77730\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 380 | loss: 0.77730 - acc: 0.9052 -- iter: 27/27\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.76635\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 381 | loss: 0.76635 - acc: 0.9073 -- iter: 27/27\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.75617\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 382 | loss: 0.75617 - acc: 0.9092 -- iter: 27/27\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.74666\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 383 | loss: 0.74666 - acc: 0.9108 -- iter: 27/27\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.73776\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 384 | loss: 0.73776 - acc: 0.9123 -- iter: 27/27\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.72941\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 385 | loss: 0.72941 - acc: 0.9137 -- iter: 27/27\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.72154\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 386 | loss: 0.72154 - acc: 0.9149 -- iter: 27/27\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.71412\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 387 | loss: 0.71412 - acc: 0.9160 -- iter: 27/27\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.70709\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 388 | loss: 0.70709 - acc: 0.9170 -- iter: 27/27\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.70041\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 389 | loss: 0.70041 - acc: 0.9179 -- iter: 27/27\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69405\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 390 | loss: 0.69405 - acc: 0.9187 -- iter: 27/27\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.68798\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 391 | loss: 0.68798 - acc: 0.9194 -- iter: 27/27\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.68217\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 392 | loss: 0.68217 - acc: 0.9201 -- iter: 27/27\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.67659\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 393 | loss: 0.67659 - acc: 0.9207 -- iter: 27/27\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.92002\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 394 | loss: 0.92002 - acc: 0.8508 -- iter: 27/27\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.89010\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 395 | loss: 0.89010 - acc: 0.8583 -- iter: 27/27\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.86293\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 396 | loss: 0.86293 - acc: 0.8651 -- iter: 27/27\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.83825\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 397 | loss: 0.83825 - acc: 0.8712 -- iter: 27/27\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.81578\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 398 | loss: 0.81578 - acc: 0.8766 -- iter: 27/27\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.79530\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 399 | loss: 0.79530 - acc: 0.8816 -- iter: 27/27\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.77661\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 400 | loss: 0.77661 - acc: 0.8860 -- iter: 27/27\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.75951\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 401 | loss: 0.75951 - acc: 0.8900 -- iter: 27/27\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m1.13997\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 402 | loss: 1.13997 - acc: 0.8121 -- iter: 27/27\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m1.08617\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 403 | loss: 1.08617 - acc: 0.8235 -- iter: 27/27\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m1.03765\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 404 | loss: 1.03765 - acc: 0.8337 -- iter: 27/27\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.99385\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 405 | loss: 0.99385 - acc: 0.8430 -- iter: 27/27\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.95429\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 406 | loss: 0.95429 - acc: 0.8513 -- iter: 27/27\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.91851\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 407 | loss: 0.91851 - acc: 0.8587 -- iter: 27/27\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.88613\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 408 | loss: 0.88613 - acc: 0.8654 -- iter: 27/27\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.85680\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 409 | loss: 0.85680 - acc: 0.8715 -- iter: 27/27\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m1.15136\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 410 | loss: 1.15136 - acc: 0.8066 -- iter: 27/27\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m1.09523\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 411 | loss: 1.09523 - acc: 0.8185 -- iter: 27/27\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m1.45505\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 412 | loss: 1.45505 - acc: 0.7404 -- iter: 27/27\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m1.36855\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 413 | loss: 1.36855 - acc: 0.7589 -- iter: 27/27\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m1.65571\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 414 | loss: 1.65571 - acc: 0.6941 -- iter: 27/27\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m1.54938\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 415 | loss: 1.54938 - acc: 0.7210 -- iter: 27/27\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m1.45382\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 416 | loss: 1.45382 - acc: 0.7452 -- iter: 27/27\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m1.36791\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 417 | loss: 1.36791 - acc: 0.7670 -- iter: 27/27\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m1.29065\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 418 | loss: 1.29065 - acc: 0.7866 -- iter: 27/27\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m1.22113\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 419 | loss: 1.22113 - acc: 0.8042 -- iter: 27/27\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m1.15855\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 420 | loss: 1.15855 - acc: 0.8201 -- iter: 27/27\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m1.10219\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 421 | loss: 1.10219 - acc: 0.8344 -- iter: 27/27\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m1.05139\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 422 | loss: 1.05139 - acc: 0.8472 -- iter: 27/27\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m1.00556\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 423 | loss: 1.00556 - acc: 0.8588 -- iter: 27/27\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.96421\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 424 | loss: 0.96421 - acc: 0.8692 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.92685\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 425 | loss: 0.92685 - acc: 0.8786 -- iter: 27/27\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.89306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 426 | loss: 0.89306 - acc: 0.8870 -- iter: 27/27\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.86248\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 427 | loss: 0.86248 - acc: 0.8946 -- iter: 27/27\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.83476\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 428 | loss: 0.83476 - acc: 0.9015 -- iter: 27/27\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.80962\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 429 | loss: 0.80962 - acc: 0.9076 -- iter: 27/27\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.78678\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 430 | loss: 0.78678 - acc: 0.9131 -- iter: 27/27\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.76599\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 431 | loss: 0.76599 - acc: 0.9181 -- iter: 27/27\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.74705\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 432 | loss: 0.74705 - acc: 0.9226 -- iter: 27/27\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.72977\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 433 | loss: 0.72977 - acc: 0.9266 -- iter: 27/27\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.71396\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 434 | loss: 0.71396 - acc: 0.9303 -- iter: 27/27\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69947\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 435 | loss: 0.69947 - acc: 0.9335 -- iter: 27/27\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.68618\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 436 | loss: 0.68618 - acc: 0.9365 -- iter: 27/27\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.67395\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 437 | loss: 0.67395 - acc: 0.9391 -- iter: 27/27\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.66268\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 438 | loss: 0.66268 - acc: 0.9415 -- iter: 27/27\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.65226\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 439 | loss: 0.65226 - acc: 0.9437 -- iter: 27/27\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.64262\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 440 | loss: 0.64262 - acc: 0.9456 -- iter: 27/27\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.63365\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 441 | loss: 0.63365 - acc: 0.9473 -- iter: 27/27\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.62530\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 442 | loss: 0.62530 - acc: 0.9489 -- iter: 27/27\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.61751\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 443 | loss: 0.61751 - acc: 0.9503 -- iter: 27/27\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.61020\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 444 | loss: 0.61020 - acc: 0.9516 -- iter: 27/27\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.60335\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 445 | loss: 0.60335 - acc: 0.9527 -- iter: 27/27\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.59690\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 446 | loss: 0.59690 - acc: 0.9537 -- iter: 27/27\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.59081\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 447 | loss: 0.59081 - acc: 0.9547 -- iter: 27/27\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.58504\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 448 | loss: 0.58504 - acc: 0.9555 -- iter: 27/27\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.57957\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 449 | loss: 0.57957 - acc: 0.9562 -- iter: 27/27\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.86352\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 450 | loss: 0.86352 - acc: 0.8865 -- iter: 27/27\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.82976\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 451 | loss: 0.82976 - acc: 0.8942 -- iter: 27/27\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.79920\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 452 | loss: 0.79920 - acc: 0.9011 -- iter: 27/27\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.77151\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 453 | loss: 0.77151 - acc: 0.9072 -- iter: 27/27\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m1.04803\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 454 | loss: 1.04803 - acc: 0.8387 -- iter: 27/27\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.99519\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 455 | loss: 0.99519 - acc: 0.8512 -- iter: 27/27\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.94754\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 456 | loss: 0.94754 - acc: 0.8623 -- iter: 27/27\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.90455\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 457 | loss: 0.90455 - acc: 0.8724 -- iter: 27/27\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m1.23019\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 458 | loss: 1.23019 - acc: 0.7889 -- iter: 27/27\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m1.15880\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 459 | loss: 1.15880 - acc: 0.8063 -- iter: 27/27\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m1.09453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 460 | loss: 1.09453 - acc: 0.8219 -- iter: 27/27\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m1.03664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 461 | loss: 1.03664 - acc: 0.8361 -- iter: 27/27\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m1.28869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 462 | loss: 1.28869 - acc: 0.7747 -- iter: 27/27\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m1.21136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 463 | loss: 1.21136 - acc: 0.7935 -- iter: 27/27\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m1.14177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 464 | loss: 1.14177 - acc: 0.8104 -- iter: 27/27\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m1.07912\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 465 | loss: 1.07912 - acc: 0.8257 -- iter: 27/27\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m1.35703\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 466 | loss: 1.35703 - acc: 0.7468 -- iter: 27/27\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m1.27290\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 467 | loss: 1.27290 - acc: 0.7684 -- iter: 27/27\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m1.19724\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 468 | loss: 1.19724 - acc: 0.7879 -- iter: 27/27\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m1.12915\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 469 | loss: 1.12915 - acc: 0.8054 -- iter: 27/27\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m1.06786\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 470 | loss: 1.06786 - acc: 0.8212 -- iter: 27/27\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m1.01266\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 471 | loss: 1.01266 - acc: 0.8353 -- iter: 27/27\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m1.37845\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 472 | loss: 1.37845 - acc: 0.7666 -- iter: 27/27\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m1.29221\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 473 | loss: 1.29221 - acc: 0.7863 -- iter: 27/27\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m1.21465\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 474 | loss: 1.21465 - acc: 0.8039 -- iter: 27/27\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m1.14487\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 475 | loss: 1.14487 - acc: 0.8198 -- iter: 27/27\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m1.08206\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 476 | loss: 1.08206 - acc: 0.8341 -- iter: 27/27\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m1.02549\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 477 | loss: 1.02549 - acc: 0.8470 -- iter: 27/27\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m1.36933\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 478 | loss: 1.36933 - acc: 0.7808 -- iter: 27/27\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m1.28404\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 479 | loss: 1.28404 - acc: 0.7991 -- iter: 27/27\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m1.20734\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 480 | loss: 1.20734 - acc: 0.8154 -- iter: 27/27\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m1.13832\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 481 | loss: 1.13832 - acc: 0.8302 -- iter: 27/27\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m1.07618\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 482 | loss: 1.07618 - acc: 0.8435 -- iter: 27/27\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m1.02021\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 483 | loss: 1.02021 - acc: 0.8554 -- iter: 27/27\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.96978\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 484 | loss: 0.96978 - acc: 0.8662 -- iter: 27/27\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.92429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 485 | loss: 0.92429 - acc: 0.8759 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.88325\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 486 | loss: 0.88325 - acc: 0.8846 -- iter: 27/27\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.84618\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 487 | loss: 0.84618 - acc: 0.8924 -- iter: 27/27\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.81268\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 488 | loss: 0.81268 - acc: 0.8995 -- iter: 27/27\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.78237\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 489 | loss: 0.78237 - acc: 0.9058 -- iter: 27/27\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.75492\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 490 | loss: 0.75492 - acc: 0.9115 -- iter: 27/27\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.73003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 491 | loss: 0.73003 - acc: 0.9167 -- iter: 27/27\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m1.16445\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 492 | loss: 1.16445 - acc: 0.8361 -- iter: 27/27\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m1.09842\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 493 | loss: 1.09842 - acc: 0.8488 -- iter: 27/27\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m1.03898\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 494 | loss: 1.03898 - acc: 0.8602 -- iter: 27/27\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.98543\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 495 | loss: 0.98543 - acc: 0.8705 -- iter: 27/27\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.93717\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 496 | loss: 0.93717 - acc: 0.8797 -- iter: 27/27\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.89364\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 497 | loss: 0.89364 - acc: 0.8881 -- iter: 27/27\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.85436\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 498 | loss: 0.85436 - acc: 0.8956 -- iter: 27/27\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.81888\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 499 | loss: 0.81888 - acc: 0.9023 -- iter: 27/27\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.78680\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 500 | loss: 0.78680 - acc: 0.9084 -- iter: 27/27\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.75778\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 501 | loss: 0.75778 - acc: 0.9138 -- iter: 27/27\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.73149\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 502 | loss: 0.73149 - acc: 0.9187 -- iter: 27/27\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.70766\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 503 | loss: 0.70766 - acc: 0.9232 -- iter: 27/27\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.68601\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 504 | loss: 0.68601 - acc: 0.9271 -- iter: 27/27\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.66634\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 505 | loss: 0.66634 - acc: 0.9307 -- iter: 27/27\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.96750\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 506 | loss: 0.96750 - acc: 0.8599 -- iter: 27/27\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.91939\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 507 | loss: 0.91939 - acc: 0.8702 -- iter: 27/27\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.87600\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 508 | loss: 0.87600 - acc: 0.8795 -- iter: 27/27\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.83684\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 509 | loss: 0.83684 - acc: 0.8878 -- iter: 27/27\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.80147\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 510 | loss: 0.80147 - acc: 0.8953 -- iter: 27/27\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.76949\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 511 | loss: 0.76949 - acc: 0.9021 -- iter: 27/27\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.74056\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 512 | loss: 0.74056 - acc: 0.9082 -- iter: 27/27\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.71435\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 513 | loss: 0.71435 - acc: 0.9137 -- iter: 27/27\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69060\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 514 | loss: 0.69060 - acc: 0.9186 -- iter: 27/27\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.66903\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 515 | loss: 0.66903 - acc: 0.9230 -- iter: 27/27\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.64943\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 516 | loss: 0.64943 - acc: 0.9270 -- iter: 27/27\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.63159\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 517 | loss: 0.63159 - acc: 0.9306 -- iter: 27/27\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.61533\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 518 | loss: 0.61533 - acc: 0.9338 -- iter: 27/27\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.60050\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 519 | loss: 0.60050 - acc: 0.9368 -- iter: 27/27\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.58694\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 520 | loss: 0.58694 - acc: 0.9394 -- iter: 27/27\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.57451\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 521 | loss: 0.57451 - acc: 0.9417 -- iter: 27/27\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.56311\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 522 | loss: 0.56311 - acc: 0.9439 -- iter: 27/27\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.55262\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 523 | loss: 0.55262 - acc: 0.9458 -- iter: 27/27\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.54296\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 524 | loss: 0.54296 - acc: 0.9475 -- iter: 27/27\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.53405\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 525 | loss: 0.53405 - acc: 0.9490 -- iter: 27/27\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.52579\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 526 | loss: 0.52579 - acc: 0.9504 -- iter: 27/27\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.51814\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 527 | loss: 0.51814 - acc: 0.9517 -- iter: 27/27\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.51102\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 528 | loss: 0.51102 - acc: 0.9528 -- iter: 27/27\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.50438\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 529 | loss: 0.50438 - acc: 0.9538 -- iter: 27/27\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.49818\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 530 | loss: 0.49818 - acc: 0.9547 -- iter: 27/27\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.49237\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 531 | loss: 0.49237 - acc: 0.9556 -- iter: 27/27\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.48691\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 532 | loss: 0.48691 - acc: 0.9563 -- iter: 27/27\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.48176\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 533 | loss: 0.48176 - acc: 0.9570 -- iter: 27/27\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.47690\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 534 | loss: 0.47690 - acc: 0.9576 -- iter: 27/27\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.47230\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 535 | loss: 0.47230 - acc: 0.9581 -- iter: 27/27\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.46792\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 536 | loss: 0.46792 - acc: 0.9586 -- iter: 27/27\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.46375\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 537 | loss: 0.46375 - acc: 0.9590 -- iter: 27/27\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.85801\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 538 | loss: 0.85801 - acc: 0.8742 -- iter: 27/27\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.81453\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 539 | loss: 0.81453 - acc: 0.8831 -- iter: 27/27\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.21302\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 540 | loss: 1.21302 - acc: 0.8059 -- iter: 27/27\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m1.13397\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 541 | loss: 1.13397 - acc: 0.8216 -- iter: 27/27\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m1.06284\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 542 | loss: 1.06284 - acc: 0.8358 -- iter: 27/27\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.99881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 543 | loss: 0.99881 - acc: 0.8485 -- iter: 27/27\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.94115\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 544 | loss: 0.94115 - acc: 0.8599 -- iter: 27/27\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.88922\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 545 | loss: 0.88922 - acc: 0.8702 -- iter: 27/27\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m1.26249\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 546 | loss: 1.26249 - acc: 0.8017 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m1.17842\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 547 | loss: 1.17842 - acc: 0.8178 -- iter: 27/27\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m1.10281\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 548 | loss: 1.10281 - acc: 0.8324 -- iter: 27/27\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m1.03476\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 549 | loss: 1.03476 - acc: 0.8454 -- iter: 27/27\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.97351\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 550 | loss: 0.97351 - acc: 0.8572 -- iter: 27/27\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.91835\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 551 | loss: 0.91835 - acc: 0.8678 -- iter: 27/27\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.86866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 552 | loss: 0.86866 - acc: 0.8773 -- iter: 27/27\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.82386\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 553 | loss: 0.82386 - acc: 0.8858 -- iter: 27/27\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.78347\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 554 | loss: 0.78347 - acc: 0.8936 -- iter: 27/27\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.74701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 555 | loss: 0.74701 - acc: 0.9005 -- iter: 27/27\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m1.17080\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 556 | loss: 1.17080 - acc: 0.8179 -- iter: 27/27\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m1.09556\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 557 | loss: 1.09556 - acc: 0.8324 -- iter: 27/27\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m1.02786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 558 | loss: 1.02786 - acc: 0.8454 -- iter: 27/27\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.96694\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 559 | loss: 0.96694 - acc: 0.8572 -- iter: 27/27\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m1.24161\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 560 | loss: 1.24161 - acc: 0.7937 -- iter: 27/27\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m1.15937\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 561 | loss: 1.15937 - acc: 0.8106 -- iter: 27/27\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m1.08541\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 562 | loss: 1.08541 - acc: 0.8258 -- iter: 27/27\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m1.01887\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 563 | loss: 1.01887 - acc: 0.8396 -- iter: 27/27\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.95898\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 564 | loss: 0.95898 - acc: 0.8519 -- iter: 27/27\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.90505\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 565 | loss: 0.90505 - acc: 0.8630 -- iter: 27/27\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.85648\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 566 | loss: 0.85648 - acc: 0.8730 -- iter: 27/27\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.81270\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 567 | loss: 0.81270 - acc: 0.8820 -- iter: 27/27\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m1.13232\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 568 | loss: 1.13232 - acc: 0.7938 -- iter: 27/27\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m1.06092\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 569 | loss: 1.06092 - acc: 0.8107 -- iter: 27/27\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m1.41753\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 570 | loss: 1.41753 - acc: 0.7370 -- iter: 27/27\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m1.31777\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 571 | loss: 1.31777 - acc: 0.7596 -- iter: 27/27\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m1.22811\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 572 | loss: 1.22811 - acc: 0.7800 -- iter: 27/27\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m1.14748\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 573 | loss: 1.14748 - acc: 0.7983 -- iter: 27/27\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m1.07497\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 574 | loss: 1.07497 - acc: 0.8147 -- iter: 27/27\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m1.00973\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 575 | loss: 1.00973 - acc: 0.8296 -- iter: 27/27\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.95101\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 576 | loss: 0.95101 - acc: 0.8429 -- iter: 27/27\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.89814\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 577 | loss: 0.89814 - acc: 0.8549 -- iter: 27/27\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.85050\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 578 | loss: 0.85050 - acc: 0.8657 -- iter: 27/27\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.80757\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 579 | loss: 0.80757 - acc: 0.8754 -- iter: 27/27\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m1.11105\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 580 | loss: 1.11105 - acc: 0.7990 -- iter: 27/27\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m1.04200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 581 | loss: 1.04200 - acc: 0.8154 -- iter: 27/27\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.97986\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 582 | loss: 0.97986 - acc: 0.8302 -- iter: 27/27\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.92391\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 583 | loss: 0.92391 - acc: 0.8434 -- iter: 27/27\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.87351\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 584 | loss: 0.87351 - acc: 0.8554 -- iter: 27/27\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.82809\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 585 | loss: 0.82809 - acc: 0.8661 -- iter: 27/27\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.78714\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 586 | loss: 0.78714 - acc: 0.8758 -- iter: 27/27\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.75018\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 587 | loss: 0.75018 - acc: 0.8845 -- iter: 27/27\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.71682\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 588 | loss: 0.71682 - acc: 0.8924 -- iter: 27/27\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.68667\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 589 | loss: 0.68667 - acc: 0.8994 -- iter: 27/27\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.65940\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 590 | loss: 0.65940 - acc: 0.9058 -- iter: 27/27\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.63472\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 591 | loss: 0.63472 - acc: 0.9115 -- iter: 27/27\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.61236\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 592 | loss: 0.61236 - acc: 0.9167 -- iter: 27/27\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.59207\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 593 | loss: 0.59207 - acc: 0.9213 -- iter: 27/27\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.57365\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 594 | loss: 0.57365 - acc: 0.9255 -- iter: 27/27\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.55690\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 595 | loss: 0.55690 - acc: 0.9292 -- iter: 27/27\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.54165\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 596 | loss: 0.54165 - acc: 0.9326 -- iter: 27/27\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.52775\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 597 | loss: 0.52775 - acc: 0.9356 -- iter: 27/27\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.51505\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 598 | loss: 0.51505 - acc: 0.9384 -- iter: 27/27\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.50344\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 599 | loss: 0.50344 - acc: 0.9408 -- iter: 27/27\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.49280\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 600 | loss: 0.49280 - acc: 0.9430 -- iter: 27/27\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.48303\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 601 | loss: 0.48303 - acc: 0.9450 -- iter: 27/27\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.88250\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 602 | loss: 0.88250 - acc: 0.8727 -- iter: 27/27\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.83351\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 603 | loss: 0.83351 - acc: 0.8818 -- iter: 27/27\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.78934\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 604 | loss: 0.78934 - acc: 0.8899 -- iter: 27/27\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.74950\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 605 | loss: 0.74950 - acc: 0.8972 -- iter: 27/27\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.71355\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 606 | loss: 0.71355 - acc: 0.9038 -- iter: 27/27\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.68108\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 607 | loss: 0.68108 - acc: 0.9097 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.65175\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 608 | loss: 0.65175 - acc: 0.9150 -- iter: 27/27\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.62522\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 609 | loss: 0.62522 - acc: 0.9198 -- iter: 27/27\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.60120\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 610 | loss: 0.60120 - acc: 0.9241 -- iter: 27/27\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.57944\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 611 | loss: 0.57944 - acc: 0.9280 -- iter: 27/27\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.55971\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 612 | loss: 0.55971 - acc: 0.9315 -- iter: 27/27\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.54179\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 613 | loss: 0.54179 - acc: 0.9347 -- iter: 27/27\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.52551\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 614 | loss: 0.52551 - acc: 0.9375 -- iter: 27/27\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.51069\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 615 | loss: 0.51069 - acc: 0.9400 -- iter: 27/27\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.49719\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 616 | loss: 0.49719 - acc: 0.9423 -- iter: 27/27\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.48487\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 617 | loss: 0.48487 - acc: 0.9444 -- iter: 27/27\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.47360\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 618 | loss: 0.47360 - acc: 0.9462 -- iter: 27/27\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.46329\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 619 | loss: 0.46329 - acc: 0.9479 -- iter: 27/27\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.45383\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 620 | loss: 0.45383 - acc: 0.9494 -- iter: 27/27\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.44514\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 621 | loss: 0.44514 - acc: 0.9508 -- iter: 27/27\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.43713\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 622 | loss: 0.43713 - acc: 0.9520 -- iter: 27/27\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.42975\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 623 | loss: 0.42975 - acc: 0.9531 -- iter: 27/27\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.42292\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 624 | loss: 0.42292 - acc: 0.9541 -- iter: 27/27\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.41659\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 625 | loss: 0.41659 - acc: 0.9550 -- iter: 27/27\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.41072\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 626 | loss: 0.41072 - acc: 0.9558 -- iter: 27/27\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.40525\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 627 | loss: 0.40525 - acc: 0.9565 -- iter: 27/27\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.40014\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 628 | loss: 0.40014 - acc: 0.9571 -- iter: 27/27\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.39536\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 629 | loss: 0.39536 - acc: 0.9577 -- iter: 27/27\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.39088\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 630 | loss: 0.39088 - acc: 0.9582 -- iter: 27/27\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.38666\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 631 | loss: 0.38666 - acc: 0.9587 -- iter: 27/27\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.38269\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 632 | loss: 0.38269 - acc: 0.9591 -- iter: 27/27\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.37892\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 633 | loss: 0.37892 - acc: 0.9595 -- iter: 27/27\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.37536\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 634 | loss: 0.37536 - acc: 0.9599 -- iter: 27/27\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.37197\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 635 | loss: 0.37197 - acc: 0.9602 -- iter: 27/27\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.36874\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 636 | loss: 0.36874 - acc: 0.9605 -- iter: 27/27\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.36565\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 637 | loss: 0.36565 - acc: 0.9607 -- iter: 27/27\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.36270\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 638 | loss: 0.36270 - acc: 0.9609 -- iter: 27/27\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.35986\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 639 | loss: 0.35986 - acc: 0.9611 -- iter: 27/27\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.35713\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 640 | loss: 0.35713 - acc: 0.9613 -- iter: 27/27\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.35449\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 641 | loss: 0.35449 - acc: 0.9615 -- iter: 27/27\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.35195\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 642 | loss: 0.35195 - acc: 0.9616 -- iter: 27/27\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.34948\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 643 | loss: 0.34948 - acc: 0.9618 -- iter: 27/27\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.34709\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 644 | loss: 0.34709 - acc: 0.9619 -- iter: 27/27\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.34477\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 645 | loss: 0.34477 - acc: 0.9620 -- iter: 27/27\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.34250\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 646 | loss: 0.34250 - acc: 0.9621 -- iter: 27/27\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.34030\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 647 | loss: 0.34030 - acc: 0.9622 -- iter: 27/27\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.33814\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 648 | loss: 0.33814 - acc: 0.9623 -- iter: 27/27\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.33603\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 649 | loss: 0.33603 - acc: 0.9623 -- iter: 27/27\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.33397\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 650 | loss: 0.33397 - acc: 0.9624 -- iter: 27/27\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.33194\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 651 | loss: 0.33194 - acc: 0.9624 -- iter: 27/27\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.32996\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 652 | loss: 0.32996 - acc: 0.9625 -- iter: 27/27\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.32801\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 653 | loss: 0.32801 - acc: 0.9625 -- iter: 27/27\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.32608\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 654 | loss: 0.32608 - acc: 0.9626 -- iter: 27/27\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.32419\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 655 | loss: 0.32419 - acc: 0.9626 -- iter: 27/27\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.32232\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 656 | loss: 0.32232 - acc: 0.9627 -- iter: 27/27\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.32049\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 657 | loss: 0.32049 - acc: 0.9627 -- iter: 27/27\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.31867\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 658 | loss: 0.31867 - acc: 0.9627 -- iter: 27/27\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.31688\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 659 | loss: 0.31688 - acc: 0.9627 -- iter: 27/27\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.80432\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 660 | loss: 0.80432 - acc: 0.8776 -- iter: 27/27\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.75377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 661 | loss: 0.75377 - acc: 0.8861 -- iter: 27/27\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.70824\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 662 | loss: 0.70824 - acc: 0.8938 -- iter: 27/27\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.66722\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 663 | loss: 0.66722 - acc: 0.9007 -- iter: 27/27\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.63023\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 664 | loss: 0.63023 - acc: 0.9069 -- iter: 27/27\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.59687\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 665 | loss: 0.59687 - acc: 0.9125 -- iter: 27/27\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.56677\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 666 | loss: 0.56677 - acc: 0.9176 -- iter: 27/27\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.53960\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 667 | loss: 0.53960 - acc: 0.9221 -- iter: 27/27\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.51505\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 668 | loss: 0.51505 - acc: 0.9262 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.49286\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 669 | loss: 0.49286 - acc: 0.9299 -- iter: 27/27\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.47279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 670 | loss: 0.47279 - acc: 0.9332 -- iter: 27/27\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.45462\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 671 | loss: 0.45462 - acc: 0.9362 -- iter: 27/27\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.43815\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 672 | loss: 0.43815 - acc: 0.9388 -- iter: 27/27\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.42322\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 673 | loss: 0.42322 - acc: 0.9413 -- iter: 27/27\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.40967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 674 | loss: 0.40967 - acc: 0.9434 -- iter: 27/27\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.39735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 675 | loss: 0.39735 - acc: 0.9454 -- iter: 27/27\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.38613\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 676 | loss: 0.38613 - acc: 0.9471 -- iter: 27/27\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.37592\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 677 | loss: 0.37592 - acc: 0.9487 -- iter: 27/27\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.36660\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 678 | loss: 0.36660 - acc: 0.9501 -- iter: 27/27\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.35808\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 679 | loss: 0.35808 - acc: 0.9514 -- iter: 27/27\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.72119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 680 | loss: 0.72119 - acc: 0.8785 -- iter: 27/27\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.67705\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 681 | loss: 0.67705 - acc: 0.8870 -- iter: 27/27\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.63729\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 682 | loss: 0.63729 - acc: 0.8946 -- iter: 27/27\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.60145\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 683 | loss: 0.60145 - acc: 0.9014 -- iter: 27/27\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.96566\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 684 | loss: 0.96566 - acc: 0.8446 -- iter: 27/27\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.89695\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 685 | loss: 0.89695 - acc: 0.8564 -- iter: 27/27\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.83512\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 686 | loss: 0.83512 - acc: 0.8671 -- iter: 27/27\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.77948\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 687 | loss: 0.77948 - acc: 0.8767 -- iter: 27/27\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m1.35677\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 688 | loss: 1.35677 - acc: 0.8001 -- iter: 27/27\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m1.24907\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 689 | loss: 1.24907 - acc: 0.8164 -- iter: 27/27\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m1.64448\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 690 | loss: 1.64448 - acc: 0.7422 -- iter: 27/27\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m1.50831\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 691 | loss: 1.50831 - acc: 0.7642 -- iter: 27/27\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m1.38591\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 692 | loss: 1.38591 - acc: 0.7841 -- iter: 27/27\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m1.27588\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 693 | loss: 1.27588 - acc: 0.8020 -- iter: 27/27\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m1.17697\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 694 | loss: 1.17697 - acc: 0.8181 -- iter: 27/27\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m1.08803\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 695 | loss: 1.08803 - acc: 0.8326 -- iter: 27/27\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m1.00804\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 696 | loss: 1.00804 - acc: 0.8456 -- iter: 27/27\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.93609\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 697 | loss: 0.93609 - acc: 0.8574 -- iter: 27/27\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.87135\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 698 | loss: 0.87135 - acc: 0.8679 -- iter: 27/27\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.81309\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 699 | loss: 0.81309 - acc: 0.8774 -- iter: 27/27\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.76064\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 700 | loss: 0.76064 - acc: 0.8860 -- iter: 27/27\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.71341\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 701 | loss: 0.71341 - acc: 0.8937 -- iter: 27/27\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.67087\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 702 | loss: 0.67087 - acc: 0.9006 -- iter: 27/27\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.63252\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 703 | loss: 0.63252 - acc: 0.9068 -- iter: 27/27\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.59795\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 704 | loss: 0.59795 - acc: 0.9125 -- iter: 27/27\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.56677\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 705 | loss: 0.56677 - acc: 0.9175 -- iter: 27/27\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.53862\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 706 | loss: 0.53862 - acc: 0.9220 -- iter: 27/27\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.51321\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 707 | loss: 0.51321 - acc: 0.9261 -- iter: 27/27\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.93364\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 708 | loss: 0.93364 - acc: 0.8557 -- iter: 27/27\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.86864\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 709 | loss: 0.86864 - acc: 0.8665 -- iter: 27/27\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.81014\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 710 | loss: 0.81014 - acc: 0.8761 -- iter: 27/27\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.75748\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 711 | loss: 0.75748 - acc: 0.8848 -- iter: 27/27\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m1.14492\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 712 | loss: 1.14492 - acc: 0.8074 -- iter: 27/27\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m1.05882\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 713 | loss: 1.05882 - acc: 0.8230 -- iter: 27/27\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m1.44444\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 714 | loss: 1.44444 - acc: 0.7481 -- iter: 27/27\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m1.32859\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 715 | loss: 1.32859 - acc: 0.7696 -- iter: 27/27\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m1.66409\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 716 | loss: 1.66409 - acc: 0.6963 -- iter: 27/27\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m1.52661\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 717 | loss: 1.52661 - acc: 0.7230 -- iter: 27/27\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m1.40307\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 718 | loss: 1.40307 - acc: 0.7470 -- iter: 27/27\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m1.29204\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 719 | loss: 1.29204 - acc: 0.7686 -- iter: 27/27\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m1.19223\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 720 | loss: 1.19223 - acc: 0.7917 -- iter: 27/27\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m1.10250\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 721 | loss: 1.10250 - acc: 0.8126 -- iter: 27/27\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m1.02182\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 722 | loss: 1.02182 - acc: 0.8313 -- iter: 27/27\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.94925\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 723 | loss: 0.94925 - acc: 0.8482 -- iter: 27/27\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.88397\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 724 | loss: 0.88397 - acc: 0.8634 -- iter: 27/27\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.82523\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 725 | loss: 0.82523 - acc: 0.8770 -- iter: 27/27\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.77235\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 726 | loss: 0.77235 - acc: 0.8893 -- iter: 27/27\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.72474\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 727 | loss: 0.72474 - acc: 0.9004 -- iter: 27/27\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.68184\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 728 | loss: 0.68184 - acc: 0.9103 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.64319\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 729 | loss: 0.64319 - acc: 0.9193 -- iter: 27/27\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m1.03908\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 730 | loss: 1.03908 - acc: 0.8385 -- iter: 27/27\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.96468\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 731 | loss: 0.96468 - acc: 0.8546 -- iter: 27/27\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.89775\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 732 | loss: 0.89775 - acc: 0.8692 -- iter: 27/27\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.83752\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 733 | loss: 0.83752 - acc: 0.8823 -- iter: 27/27\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.78331\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 734 | loss: 0.78331 - acc: 0.8940 -- iter: 27/27\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.73448\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 735 | loss: 0.73448 - acc: 0.9046 -- iter: 27/27\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.69050\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 736 | loss: 0.69050 - acc: 0.9142 -- iter: 27/27\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.65087\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 737 | loss: 0.65087 - acc: 0.9228 -- iter: 27/27\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.61513\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 738 | loss: 0.61513 - acc: 0.9305 -- iter: 27/27\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.58290\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 739 | loss: 0.58290 - acc: 0.9374 -- iter: 27/27\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.98027\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 740 | loss: 0.98027 - acc: 0.8696 -- iter: 27/27\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.91147\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 741 | loss: 0.91147 - acc: 0.8827 -- iter: 27/27\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.84956\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 742 | loss: 0.84956 - acc: 0.8944 -- iter: 27/27\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.79383\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 743 | loss: 0.79383 - acc: 0.9049 -- iter: 27/27\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.74366\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 744 | loss: 0.74366 - acc: 0.9145 -- iter: 27/27\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.69847\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 745 | loss: 0.69847 - acc: 0.9230 -- iter: 27/27\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m1.15813\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 746 | loss: 1.15813 - acc: 0.8492 -- iter: 27/27\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m1.07152\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 747 | loss: 1.07152 - acc: 0.8643 -- iter: 27/27\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.99362\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 748 | loss: 0.99362 - acc: 0.8779 -- iter: 27/27\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.92355\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 749 | loss: 0.92355 - acc: 0.8901 -- iter: 27/27\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m1.35991\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 750 | loss: 1.35991 - acc: 0.8085 -- iter: 27/27\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m1.25336\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 751 | loss: 1.25336 - acc: 0.8276 -- iter: 27/27\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m1.15758\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 752 | loss: 1.15758 - acc: 0.8449 -- iter: 27/27\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m1.07146\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 753 | loss: 1.07146 - acc: 0.8604 -- iter: 27/27\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.99400\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 754 | loss: 0.99400 - acc: 0.8743 -- iter: 27/27\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.92433\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 755 | loss: 0.92433 - acc: 0.8869 -- iter: 27/27\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m1.36687\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 756 | loss: 1.36687 - acc: 0.8130 -- iter: 27/27\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m1.26007\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 757 | loss: 1.26007 - acc: 0.8317 -- iter: 27/27\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m1.16405\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 758 | loss: 1.16405 - acc: 0.8486 -- iter: 27/27\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m1.07773\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 759 | loss: 1.07773 - acc: 0.8637 -- iter: 27/27\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m1.00009\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 760 | loss: 1.00009 - acc: 0.8773 -- iter: 27/27\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.93025\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 761 | loss: 0.93025 - acc: 0.8896 -- iter: 27/27\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.86741\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 762 | loss: 0.86741 - acc: 0.9006 -- iter: 27/27\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.81085\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 763 | loss: 0.81085 - acc: 0.9106 -- iter: 27/27\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.75992\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 764 | loss: 0.75992 - acc: 0.9195 -- iter: 27/27\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.71405\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 765 | loss: 0.71405 - acc: 0.9276 -- iter: 27/27\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m1.10828\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 766 | loss: 1.10828 - acc: 0.8496 -- iter: 27/27\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m1.02759\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 767 | loss: 1.02759 - acc: 0.8647 -- iter: 27/27\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.95501\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 768 | loss: 0.95501 - acc: 0.8782 -- iter: 27/27\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.88970\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 769 | loss: 0.88970 - acc: 0.8904 -- iter: 27/27\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.83092\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 770 | loss: 0.83092 - acc: 0.9013 -- iter: 27/27\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.77800\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 771 | loss: 0.77800 - acc: 0.9112 -- iter: 27/27\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m1.14898\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 772 | loss: 1.14898 - acc: 0.8312 -- iter: 27/27\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m1.06430\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 773 | loss: 1.06430 - acc: 0.8481 -- iter: 27/27\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.98814\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 774 | loss: 0.98814 - acc: 0.8633 -- iter: 27/27\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.91962\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 775 | loss: 0.91962 - acc: 0.8769 -- iter: 27/27\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m1.26056\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 776 | loss: 1.26056 - acc: 0.8041 -- iter: 27/27\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m1.16493\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 777 | loss: 1.16493 - acc: 0.8237 -- iter: 27/27\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m1.51314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 778 | loss: 1.51314 - acc: 0.7561 -- iter: 27/27\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m1.39252\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 779 | loss: 1.39252 - acc: 0.7805 -- iter: 27/27\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m1.28412\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 780 | loss: 1.28412 - acc: 0.8024 -- iter: 27/27\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m1.18668\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 781 | loss: 1.18668 - acc: 0.8222 -- iter: 27/27\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m1.09908\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 782 | loss: 1.09908 - acc: 0.8400 -- iter: 27/27\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m1.02030\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 783 | loss: 1.02030 - acc: 0.8560 -- iter: 27/27\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.94943\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 784 | loss: 0.94943 - acc: 0.8704 -- iter: 27/27\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.88567\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 785 | loss: 0.88567 - acc: 0.8833 -- iter: 27/27\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.82828\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 786 | loss: 0.82828 - acc: 0.8950 -- iter: 27/27\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.77660\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 787 | loss: 0.77660 - acc: 0.9055 -- iter: 27/27\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m1.13192\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 788 | loss: 1.13192 - acc: 0.8298 -- iter: 27/27\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m1.04990\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 789 | loss: 1.04990 - acc: 0.8468 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.97610\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 790 | loss: 0.97610 - acc: 0.8621 -- iter: 27/27\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.90971\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 791 | loss: 0.90971 - acc: 0.8759 -- iter: 27/27\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m1.25332\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 792 | loss: 1.25332 - acc: 0.8031 -- iter: 27/27\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m1.15930\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 793 | loss: 1.15930 - acc: 0.8228 -- iter: 27/27\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m1.07475\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 794 | loss: 1.07475 - acc: 0.8405 -- iter: 27/27\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.99871\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 795 | loss: 0.99871 - acc: 0.8565 -- iter: 27/27\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.93029\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 796 | loss: 0.93029 - acc: 0.8708 -- iter: 27/27\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.86872\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 797 | loss: 0.86872 - acc: 0.8837 -- iter: 27/27\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.81328\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 798 | loss: 0.81328 - acc: 0.8954 -- iter: 27/27\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.76336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 799 | loss: 0.76336 - acc: 0.9058 -- iter: 27/27\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.71837\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 800 | loss: 0.71837 - acc: 0.9153 -- iter: 27/27\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.67782\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 801 | loss: 0.67782 - acc: 0.9237 -- iter: 27/27\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.64124\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 802 | loss: 0.64124 - acc: 0.9314 -- iter: 27/27\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.60823\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 803 | loss: 0.60823 - acc: 0.9382 -- iter: 27/27\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.99809\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 804 | loss: 0.99809 - acc: 0.8629 -- iter: 27/27\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.92932\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 805 | loss: 0.92932 - acc: 0.8766 -- iter: 27/27\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.86742\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 806 | loss: 0.86742 - acc: 0.8890 -- iter: 27/27\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.81169\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 807 | loss: 0.81169 - acc: 0.9001 -- iter: 27/27\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m1.15186\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 808 | loss: 1.15186 - acc: 0.8249 -- iter: 27/27\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m1.06773\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 809 | loss: 1.06773 - acc: 0.8424 -- iter: 27/27\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.99205\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 810 | loss: 0.99205 - acc: 0.8581 -- iter: 27/27\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.92396\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 811 | loss: 0.92396 - acc: 0.8723 -- iter: 27/27\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.86269\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 812 | loss: 0.86269 - acc: 0.8851 -- iter: 27/27\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.80752\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 813 | loss: 0.80752 - acc: 0.8966 -- iter: 27/27\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.75784\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 814 | loss: 0.75784 - acc: 0.9069 -- iter: 27/27\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.71307\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 815 | loss: 0.71307 - acc: 0.9162 -- iter: 27/27\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.67272\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 816 | loss: 0.67272 - acc: 0.9246 -- iter: 27/27\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.63633\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 817 | loss: 0.63633 - acc: 0.9322 -- iter: 27/27\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.60348\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 818 | loss: 0.60348 - acc: 0.9389 -- iter: 27/27\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.57383\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 819 | loss: 0.57383 - acc: 0.9450 -- iter: 27/27\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m1.08927\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 820 | loss: 1.08927 - acc: 0.8505 -- iter: 27/27\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m1.01098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 821 | loss: 1.01098 - acc: 0.8655 -- iter: 27/27\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.94053\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 822 | loss: 0.94053 - acc: 0.8789 -- iter: 27/27\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.87714\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 823 | loss: 0.87714 - acc: 0.8910 -- iter: 27/27\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.82006\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 824 | loss: 0.82006 - acc: 0.9019 -- iter: 27/27\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.76866\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 825 | loss: 0.76866 - acc: 0.9117 -- iter: 27/27\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.72235\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 826 | loss: 0.72235 - acc: 0.9206 -- iter: 27/27\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.68061\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 827 | loss: 0.68061 - acc: 0.9285 -- iter: 27/27\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.64297\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 828 | loss: 0.64297 - acc: 0.9357 -- iter: 27/27\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.60901\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 829 | loss: 0.60901 - acc: 0.9421 -- iter: 27/27\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.57834\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 830 | loss: 0.57834 - acc: 0.9479 -- iter: 27/27\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.55064\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 831 | loss: 0.55064 - acc: 0.9531 -- iter: 27/27\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.52560\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 832 | loss: 0.52560 - acc: 0.9578 -- iter: 27/27\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.50294\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 833 | loss: 0.50294 - acc: 0.9620 -- iter: 27/27\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.87608\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 834 | loss: 0.87608 - acc: 0.8806 -- iter: 27/27\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.81823\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 835 | loss: 0.81823 - acc: 0.8926 -- iter: 27/27\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.76616\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 836 | loss: 0.76616 - acc: 0.9033 -- iter: 27/27\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.71924\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 837 | loss: 0.71924 - acc: 0.9130 -- iter: 27/27\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.67696\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 838 | loss: 0.67696 - acc: 0.9217 -- iter: 27/27\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.63885\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 839 | loss: 0.63885 - acc: 0.9295 -- iter: 27/27\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.94491\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 840 | loss: 0.94491 - acc: 0.8514 -- iter: 27/27\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.87993\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 841 | loss: 0.87993 - acc: 0.8662 -- iter: 27/27\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.82144\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 842 | loss: 0.82144 - acc: 0.8796 -- iter: 27/27\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.76877\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 843 | loss: 0.76877 - acc: 0.8917 -- iter: 27/27\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m1.12116\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 844 | loss: 1.12116 - acc: 0.8025 -- iter: 27/27\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m1.03855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 845 | loss: 1.03855 - acc: 0.8222 -- iter: 27/27\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.96425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 846 | loss: 0.96425 - acc: 0.8400 -- iter: 27/27\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.89739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 847 | loss: 0.89739 - acc: 0.8560 -- iter: 27/27\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.83723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 848 | loss: 0.83723 - acc: 0.8704 -- iter: 27/27\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.78306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 849 | loss: 0.78306 - acc: 0.8834 -- iter: 27/27\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.73428\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 850 | loss: 0.73428 - acc: 0.8950 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.69033\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 851 | loss: 0.69033 - acc: 0.9055 -- iter: 27/27\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.65071\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 852 | loss: 0.65071 - acc: 0.9150 -- iter: 27/27\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.61498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 853 | loss: 0.61498 - acc: 0.9235 -- iter: 27/27\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.95564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 854 | loss: 0.95564 - acc: 0.8422 -- iter: 27/27\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.88935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 855 | loss: 0.88935 - acc: 0.8580 -- iter: 27/27\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m1.36757\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 856 | loss: 1.36757 - acc: 0.7796 -- iter: 27/27\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m1.26021\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 857 | loss: 1.26021 - acc: 0.8017 -- iter: 27/27\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m1.16370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 858 | loss: 1.16370 - acc: 0.8215 -- iter: 27/27\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m1.07690\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 859 | loss: 1.07690 - acc: 0.8393 -- iter: 27/27\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.99884\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 860 | loss: 0.99884 - acc: 0.8554 -- iter: 27/27\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.92862\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 861 | loss: 0.92862 - acc: 0.8699 -- iter: 27/27\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.86543\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 862 | loss: 0.86543 - acc: 0.8829 -- iter: 27/27\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.80855\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 863 | loss: 0.80855 - acc: 0.8946 -- iter: 27/27\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m1.17227\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 864 | loss: 1.17227 - acc: 0.8125 -- iter: 27/27\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m1.08475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 865 | loss: 1.08475 - acc: 0.8313 -- iter: 27/27\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m1.00605\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 866 | loss: 1.00605 - acc: 0.8482 -- iter: 27/27\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.93525\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 867 | loss: 0.93525 - acc: 0.8633 -- iter: 27/27\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.87154\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 868 | loss: 0.87154 - acc: 0.8770 -- iter: 27/27\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.81420\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 869 | loss: 0.81420 - acc: 0.8893 -- iter: 27/27\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.76256\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 870 | loss: 0.76256 - acc: 0.9004 -- iter: 27/27\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.71605\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 871 | loss: 0.71605 - acc: 0.9103 -- iter: 27/27\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.67414\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 872 | loss: 0.67414 - acc: 0.9193 -- iter: 27/27\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.63636\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 873 | loss: 0.63636 - acc: 0.9274 -- iter: 27/27\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.60227\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 874 | loss: 0.60227 - acc: 0.9346 -- iter: 27/27\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.57150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 875 | loss: 0.57150 - acc: 0.9412 -- iter: 27/27\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.54372\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 876 | loss: 0.54372 - acc: 0.9471 -- iter: 27/27\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.51861\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 877 | loss: 0.51861 - acc: 0.9524 -- iter: 27/27\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.87271\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 878 | loss: 0.87271 - acc: 0.8682 -- iter: 27/27\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.81458\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 879 | loss: 0.81458 - acc: 0.8814 -- iter: 27/27\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m1.17658\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 880 | loss: 1.17658 - acc: 0.7970 -- iter: 27/27\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m1.08812\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 881 | loss: 1.08812 - acc: 0.8173 -- iter: 27/27\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m1.40010\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 882 | loss: 1.40010 - acc: 0.7430 -- iter: 27/27\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m1.28948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 883 | loss: 1.28948 - acc: 0.7687 -- iter: 27/27\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m1.19004\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 884 | loss: 1.19004 - acc: 0.7918 -- iter: 27/27\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m1.10063\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 885 | loss: 1.10063 - acc: 0.8126 -- iter: 27/27\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m1.35079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 886 | loss: 1.35079 - acc: 0.7536 -- iter: 27/27\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m1.24548\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 887 | loss: 1.24548 - acc: 0.7782 -- iter: 27/27\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m1.15080\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 888 | loss: 1.15080 - acc: 0.8004 -- iter: 27/27\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m1.06567\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 889 | loss: 1.06567 - acc: 0.8204 -- iter: 27/27\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m1.31692\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 890 | loss: 1.31692 - acc: 0.7568 -- iter: 27/27\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m1.21535\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 891 | loss: 1.21535 - acc: 0.7812 -- iter: 27/27\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m1.12402\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 892 | loss: 1.12402 - acc: 0.8030 -- iter: 27/27\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m1.04190\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 893 | loss: 1.04190 - acc: 0.8227 -- iter: 27/27\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.96803\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 894 | loss: 0.96803 - acc: 0.8405 -- iter: 27/27\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.90157\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 895 | loss: 0.90157 - acc: 0.8564 -- iter: 27/27\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.84175\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 896 | loss: 0.84175 - acc: 0.8708 -- iter: 27/27\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.78789\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 897 | loss: 0.78789 - acc: 0.8837 -- iter: 27/27\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.73937\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 898 | loss: 0.73937 - acc: 0.8953 -- iter: 27/27\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.69566\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 899 | loss: 0.69566 - acc: 0.9058 -- iter: 27/27\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m1.12731\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 900 | loss: 1.12731 - acc: 0.8226 -- iter: 27/27\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m1.04481\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 901 | loss: 1.04481 - acc: 0.8404 -- iter: 27/27\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m1.35919\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 902 | loss: 1.35919 - acc: 0.7785 -- iter: 27/27\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m1.25367\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 903 | loss: 1.25367 - acc: 0.8007 -- iter: 27/27\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m1.15879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 904 | loss: 1.15879 - acc: 0.8206 -- iter: 27/27\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m1.07348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 905 | loss: 1.07348 - acc: 0.8386 -- iter: 27/27\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.99673\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 906 | loss: 0.99673 - acc: 0.8547 -- iter: 27/27\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.92768\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 907 | loss: 0.92768 - acc: 0.8692 -- iter: 27/27\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.86554\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 908 | loss: 0.86554 - acc: 0.8823 -- iter: 27/27\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.80959\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 909 | loss: 0.80959 - acc: 0.8941 -- iter: 27/27\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.75920\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 910 | loss: 0.75920 - acc: 0.9047 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.71380\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 911 | loss: 0.71380 - acc: 0.9142 -- iter: 27/27\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m1.06896\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 912 | loss: 1.06896 - acc: 0.8302 -- iter: 27/27\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.99256\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 913 | loss: 0.99256 - acc: 0.8472 -- iter: 27/27\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.92382\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 914 | loss: 0.92382 - acc: 0.8625 -- iter: 27/27\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.86195\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 915 | loss: 0.86195 - acc: 0.8762 -- iter: 27/27\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.80625\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 916 | loss: 0.80625 - acc: 0.8886 -- iter: 27/27\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.75609\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 917 | loss: 0.75609 - acc: 0.8997 -- iter: 27/27\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.71089\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 918 | loss: 0.71089 - acc: 0.9098 -- iter: 27/27\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.67014\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 919 | loss: 0.67014 - acc: 0.9188 -- iter: 27/27\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m1.05008\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 920 | loss: 1.05008 - acc: 0.8417 -- iter: 27/27\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.97538\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 921 | loss: 0.97538 - acc: 0.8575 -- iter: 27/27\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m1.33760\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 922 | loss: 1.33760 - acc: 0.7829 -- iter: 27/27\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m1.23429\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 923 | loss: 1.23429 - acc: 0.8046 -- iter: 27/27\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m1.14141\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 924 | loss: 1.14141 - acc: 0.8242 -- iter: 27/27\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m1.05790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 925 | loss: 1.05790 - acc: 0.8417 -- iter: 27/27\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m1.39467\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 926 | loss: 1.39467 - acc: 0.7613 -- iter: 27/27\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m1.28601\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 927 | loss: 1.28601 - acc: 0.7851 -- iter: 27/27\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m1.18834\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 928 | loss: 1.18834 - acc: 0.8066 -- iter: 27/27\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m1.10050\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 929 | loss: 1.10050 - acc: 0.8260 -- iter: 27/27\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m1.02151\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 930 | loss: 1.02151 - acc: 0.8434 -- iter: 27/27\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.95044\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 931 | loss: 0.95044 - acc: 0.8590 -- iter: 27/27\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m1.30782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 932 | loss: 1.30782 - acc: 0.7805 -- iter: 27/27\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m1.20824\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 933 | loss: 1.20824 - acc: 0.8025 -- iter: 27/27\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m1.11870\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 934 | loss: 1.11870 - acc: 0.8222 -- iter: 27/27\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m1.03816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 935 | loss: 1.03816 - acc: 0.8400 -- iter: 27/27\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.96571\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 936 | loss: 0.96571 - acc: 0.8560 -- iter: 27/27\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.90051\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 937 | loss: 0.90051 - acc: 0.8704 -- iter: 27/27\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.84181\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 938 | loss: 0.84181 - acc: 0.8834 -- iter: 27/27\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.78894\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 939 | loss: 0.78894 - acc: 0.8950 -- iter: 27/27\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.74131\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 940 | loss: 0.74131 - acc: 0.9055 -- iter: 27/27\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.69838\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 941 | loss: 0.69838 - acc: 0.9150 -- iter: 27/27\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m1.08011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 942 | loss: 1.08011 - acc: 0.8457 -- iter: 27/27\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m1.00325\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 943 | loss: 1.00325 - acc: 0.8611 -- iter: 27/27\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.93410\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 944 | loss: 0.93410 - acc: 0.8750 -- iter: 27/27\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.87187\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 945 | loss: 0.87187 - acc: 0.8875 -- iter: 27/27\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.81583\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 946 | loss: 0.81583 - acc: 0.8988 -- iter: 27/27\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.76535\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 947 | loss: 0.76535 - acc: 0.9089 -- iter: 27/27\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.71986\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 948 | loss: 0.71986 - acc: 0.9180 -- iter: 27/27\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.67885\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 949 | loss: 0.67885 - acc: 0.9262 -- iter: 27/27\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.64185\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 950 | loss: 0.64185 - acc: 0.9336 -- iter: 27/27\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.60846\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 951 | loss: 0.60846 - acc: 0.9402 -- iter: 27/27\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.57831\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 952 | loss: 0.57831 - acc: 0.9462 -- iter: 27/27\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.55104\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 953 | loss: 0.55104 - acc: 0.9516 -- iter: 27/27\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.52639\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 954 | loss: 0.52639 - acc: 0.9564 -- iter: 27/27\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.50408\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 955 | loss: 0.50408 - acc: 0.9608 -- iter: 27/27\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.92485\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 956 | loss: 0.92485 - acc: 0.8721 -- iter: 27/27\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.86254\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 957 | loss: 0.86254 - acc: 0.8849 -- iter: 27/27\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.80644\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 958 | loss: 0.80644 - acc: 0.8964 -- iter: 27/27\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.75591\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 959 | loss: 0.75591 - acc: 0.9068 -- iter: 27/27\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.71037\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 960 | loss: 0.71037 - acc: 0.9161 -- iter: 27/27\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.66931\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 961 | loss: 0.66931 - acc: 0.9245 -- iter: 27/27\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m1.05625\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 962 | loss: 1.05625 - acc: 0.8506 -- iter: 27/27\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.98056\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 963 | loss: 0.98056 - acc: 0.8655 -- iter: 27/27\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.91245\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 964 | loss: 0.91245 - acc: 0.8789 -- iter: 27/27\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.85113\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 965 | loss: 0.85113 - acc: 0.8911 -- iter: 27/27\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.79593\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 966 | loss: 0.79593 - acc: 0.9019 -- iter: 27/27\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.74620\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 967 | loss: 0.74620 - acc: 0.9118 -- iter: 27/27\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.70139\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 968 | loss: 0.70139 - acc: 0.9206 -- iter: 27/27\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.66098\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 969 | loss: 0.66098 - acc: 0.9285 -- iter: 27/27\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m1.09015\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 970 | loss: 1.09015 - acc: 0.8394 -- iter: 27/27\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m1.01084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 971 | loss: 1.01084 - acc: 0.8554 -- iter: 27/27\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.93948\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 972 | loss: 0.93948 - acc: 0.8699 -- iter: 27/27\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.87526\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 973 | loss: 0.87526 - acc: 0.8829 -- iter: 27/27\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.81745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 974 | loss: 0.81745 - acc: 0.8946 -- iter: 27/27\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.76538\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 975 | loss: 0.76538 - acc: 0.9052 -- iter: 27/27\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.71848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 976 | loss: 0.71848 - acc: 0.9146 -- iter: 27/27\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.67621\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 977 | loss: 0.67621 - acc: 0.9232 -- iter: 27/27\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.63808\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 978 | loss: 0.63808 - acc: 0.9309 -- iter: 27/27\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.60368\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 979 | loss: 0.60368 - acc: 0.9378 -- iter: 27/27\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.57263\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 980 | loss: 0.57263 - acc: 0.9440 -- iter: 27/27\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.54458\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 981 | loss: 0.54458 - acc: 0.9496 -- iter: 27/27\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.51923\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 982 | loss: 0.51923 - acc: 0.9546 -- iter: 27/27\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.49630\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 983 | loss: 0.49630 - acc: 0.9592 -- iter: 27/27\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.47553\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 984 | loss: 0.47553 - acc: 0.9633 -- iter: 27/27\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.45672\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 985 | loss: 0.45672 - acc: 0.9669 -- iter: 27/27\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.43965\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 986 | loss: 0.43965 - acc: 0.9702 -- iter: 27/27\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.42416\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 987 | loss: 0.42416 - acc: 0.9732 -- iter: 27/27\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.41007\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 988 | loss: 0.41007 - acc: 0.9759 -- iter: 27/27\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.39725\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 989 | loss: 0.39725 - acc: 0.9783 -- iter: 27/27\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.81048\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 990 | loss: 0.81048 - acc: 0.8916 -- iter: 27/27\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.75745\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 991 | loss: 0.75745 - acc: 0.9024 -- iter: 27/27\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.70969\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 992 | loss: 0.70969 - acc: 0.9122 -- iter: 27/27\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.66664\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 993 | loss: 0.66664 - acc: 0.9210 -- iter: 27/27\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m1.05473\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 994 | loss: 1.05473 - acc: 0.8363 -- iter: 27/27\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.97716\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 995 | loss: 0.97716 - acc: 0.8526 -- iter: 27/27\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.90737\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 996 | loss: 0.90737 - acc: 0.8674 -- iter: 27/27\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.84456\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 997 | loss: 0.84456 - acc: 0.8806 -- iter: 27/27\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.78803\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 998 | loss: 0.78803 - acc: 0.8926 -- iter: 27/27\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.73712\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 999 | loss: 0.73712 - acc: 0.9033 -- iter: 27/27\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.69126\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 1000 | loss: 0.69126 - acc: 0.9130 -- iter: 27/27\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=32, show_metric=True)\n",
    "\n",
    "# Saving the Model\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "\n",
    "\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "    \n",
    "\n",
    "# load our saved model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # It Tokenize or Break it into the constituents parts of Sentense.\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # Stemming means to find the root of the word.\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Return the Array of Bag of Words: True or False and 0 or 1 for each word of bag that exists in the Sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "ERROR_THRESHOLD = 0.25\n",
    "\n",
    "def classify(sentence):\n",
    "    # Prediction or To Get the Posibility or Probability from the Model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # Exclude those results which are Below Threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # Sorting is Done because heigher Confidence Answer comes first.\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1])) #Tuppl -> Intent and Probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # That Means if Classification is Done then Find the Matching Tag.\n",
    "    if results:\n",
    "        # Long Loop to get the Result.\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # Tag Finding\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # Random Response from High Order Probabilities\n",
    "                    return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You- Is anyone there?\n",
      "Hello, thanks for visiting\n",
      "You- What hours are you open?\n",
      "Our hours are 9am-9pm every day\n",
      "You- What do you rent?\n",
      "We rent Yamaha, Piaggio and Vespa mopeds\n",
      "You- Are you cash only?\n",
      "We accept VISA, Mastercard and AMEX\n",
      "You- Can we rent a moped?\n",
      "Are you looking to rent today or later this week?\n",
      "You- today\n",
      "For rentals today please call 1-800-MYMOPED\n",
      "You- That's helpful\n",
      "My pleasure\n",
      "You- Goodbye\n",
      "Have a nice day\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_data = input(\"You- \")\n",
    "    answer = response(input_data)\n",
    "    answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
